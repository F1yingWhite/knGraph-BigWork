import json
import os
import requests
import time
from dotenv import load_dotenv

# 1. åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()
API_KEY = os.getenv("DS_API")
if not API_KEY:
    raise EnvironmentError("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® DS_API")

DEEPSEEK_API_URL = "https://api.deepseek.com/v1/chat/completions"
MODEL_NAME = "deepseek-chat"

# 2. å®šä¹‰ç›®æ ‡æ•°æ®ç»“æ„ (Schema)
# æˆ‘ä»¬è¦æ±‚æ¨¡å‹è¿”å›ä¸€ä¸ªåŒ…å« "nodes" å’Œ "edges" çš„ JSON
GRAPH_SCHEMA = {
    "nodes": [
        {
            "id": "å®ä½“å”¯ä¸€æ ‡è¯†(é€šå¸¸æ˜¯åç§°)",
            "label": "å®ä½“ç±»å‹(å¦‚: è¯ç‰©åç§°, åŒ–å­¦æˆåˆ†, å®éªŒè¯•å‰‚ä¸ææ–™, ä¸­è¯è¯æ€§, ç»ç»œ, ç–¾ç—…, åŠŸæ•ˆç­‰)",
            "attributes": {
                "æè¿°": "å®ä½“çš„å›ºæœ‰å±æ€§é”®å€¼å¯¹ã€‚ä¾‹å¦‚ï¼š{'é¢œè‰²': 'é»„è‰²', 'ç”¨é‡': '0.15-0.35g', 'å‘³é“': 'è‹¦'}"
            }
        }
    ],
    "edges": [
        {
            "source": "èµ·ç‚¹å®ä½“ID",
            "target": "ç»ˆç‚¹å®ä½“ID",
            "relation": "å…³ç³»åç§°(å¦‚: å«æœ‰æˆåˆ†, æ²»ç–—, å½’å±äº, æ£€æµ‹ä½¿ç”¨)"
        }
    ]
}

# 3. æ ¸å¿ƒæå–å‡½æ•°
def extract_knowledge_graph(text):
    system_prompt = (
        "ä½ æ˜¯ä¸€ä¸ªä¸­è¯çŸ¥è¯†å›¾è°±æ„å»ºä¸“å®¶ã€‚è¯·ä»æ–‡æœ¬ä¸­æå–å®ä½“(Nodes)ã€å±æ€§(Attributes)å’Œå…³ç³»(Edges)ã€‚"
        "ä¸¥æ ¼åŒºåˆ†ã€å±æ€§ã€‘å’Œã€å…³ç³»ã€‘ï¼š"
        "1. å±æ€§(Attributes)ï¼šæè¿°å®ä½“è‡ªèº«çš„ç‰¹å¾å€¼ï¼ˆå¦‚é¢œè‰²ã€æ€§çŠ¶ã€æ•°å€¼ã€äº§åœ°ã€å…·ä½“çš„ç†åŒ–æŒ‡æ ‡ï¼‰ã€‚"
        "2. å…³ç³»(Edges)ï¼šè¿æ¥ä¸¤ä¸ªç‹¬ç«‹å®ä½“çš„åŠ¨ä½œï¼ˆå¦‚'æ²»ç–—'è¿æ¥è¯ç‰©ä¸ç–¾ç—…ï¼Œ'å«æœ‰'è¿æ¥è¯ç‰©ä¸æˆåˆ†ï¼‰ã€‚"
        "è¯·ç›´æ¥è¾“å‡ºåˆæ³•çš„ JSONï¼Œä¸è¦åŒ…å« Markdown ä»£ç å—ã€‚"
    )

    user_prompt = f"""
### ä»»åŠ¡ç›®æ ‡
åˆ†æä»¥ä¸‹ä¸­è¯è¯å…¸æ–‡æœ¬ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±ç»“æ„ã€‚

### ç›®æ ‡ Schema
{json.dumps(GRAPH_SCHEMA, ensure_ascii=False, indent=2)}

### æå–è§„åˆ™
1. **ä¸»å®ä½“**ï¼šè¯åæ ‡é¢˜ï¼ˆå¦‚ï¼šä¸€æé»„èŠ±ã€ä¸é¦™ã€äººå‚ï¼‰ã€‚æ— éœ€æå–æ¤ç‰©æ¥æºä½œä¸ºnodeã€‚
2. **å±æ€§æå–**ï¼š
   - å°†â€œæ€§çŠ¶â€ï¼ˆå¦‚é¢œè‰²ã€å½¢çŠ¶ï¼‰ã€â€œç”¨æ³•ç”¨é‡â€ï¼ˆæ•°å€¼ï¼‰ã€â€œç†åŒ–å¸¸æ•°â€ï¼ˆå¦‚ç†”ç‚¹ã€æ°´åˆ†é™åˆ¶ï¼‰ä½œä¸ºä¸»å®ä½“çš„ `attributes`ã€‚
3. **å…³ç³»æå–**ï¼š
   - [è¯ç‰©] -> å«æœ‰ -> [åŒ–å­¦æˆåˆ†]
   - [è¯ç‰©] -> æ²»ç–— -> [ç–¾ç—…/ç—‡çŠ¶]
   - [è¯ç‰©] -> å½’å±äº -> [ç»ç»œ]
   - [è¯ç‰©/æˆåˆ†] -> æ£€æµ‹ä½¿ç”¨ -> [è¯•å‰‚] (å¦‚è–„å±‚è‰²è°±æ³•ä¸­ç”¨åˆ°çš„è¯•å‰‚)
   - ç­‰ç­‰

### å¾…å¤„ç†æ–‡æœ¬
{text}
"""

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ],
        "temperature": 0.0,  # è®¾ä¸º0ä»¥ä¿è¯ç»“æœç¡®å®šæ€§
        "response_format": {"type": "json_object"}
    }

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }

    try:
        print("æ­£åœ¨è¯·æ±‚ DeepSeek API è¿›è¡ŒçŸ¥è¯†æŠ½å–...")
        response = requests.post(DEEPSEEK_API_URL, headers=headers, json=payload)
        response.raise_for_status()
        
        content = response.json()["choices"][0]["message"]["content"]
        return json.loads(content)
        
    except requests.exceptions.RequestException as e:
        print(f"è¯·æ±‚å¤±è´¥: {e}")
        return None
    except json.JSONDecodeError:
        print("JSON è§£æå¤±è´¥ï¼Œæ¨¡å‹å¯èƒ½è¾“å‡ºäº†é JSON æ ¼å¼ã€‚")
        print("åŸå§‹å†…å®¹:", content)
        return None

# 5. è¿è¡Œä¸»ç¨‹åº
# if __name__ == "__main__":
#     result = extract_knowledge_graph(input_text_full)
    
#     if result:
#         # ä¸ºäº†æ–¹ä¾¿æŸ¥çœ‹ï¼Œæ‰“å°æ ¼å¼åŒ–çš„ JSON
#         print("\n" + "="*20 + " æŠ½å–ç»“æœ " + "="*20)
#         print(json.dumps(result, ensure_ascii=False, indent=2))
        
#         # ç®€å•ç»Ÿè®¡
#         node_count = len(result.get('nodes', []))
#         edge_count = len(result.get('edges', []))
#         print(f"\næŠ½å–ç»Ÿè®¡: èŠ‚ç‚¹æ•° {node_count}, å…³ç³»æ•° {edge_count}")
        
#         # æ¼”ç¤ºå¦‚ä½•è®¿é—®å±æ€§
#         print("\n--- å±æ€§è®¿é—®ç¤ºä¾‹ ---")
#         for node in result['nodes']:
#             if "attributes" in node and node["attributes"]:
#                 print(f"å®ä½“: {node['id']} | å±æ€§: {node['attributes']}")

if __name__ == "__main__":
    INPUT_JSON = "./assets/all_herbs_data.json"
    OUTPUT_FILE = "./assets/final_knowledge_graph_results.json"

    if not os.path.exists(INPUT_JSON):
        print(f"æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {INPUT_JSON}")
        exit()

    with open(INPUT_JSON, 'r', encoding='utf-8') as f:
        herbs_data = json.load(f)

    print(f"âœ… åŠ è½½æˆåŠŸï¼Œå…± {len(herbs_data)} æ¡è¯æã€‚")

    # å¦‚æœè¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆåˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨çš„å¼€å¤´
    if not os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            f.write("[\n") 
    
    # è·å–å·²ç»å¤„ç†è¿‡çš„è¯ææ•°é‡ï¼ˆç®€å•çš„æ–­ç‚¹ç»­ä¼ é€»è¾‘ï¼‰
    processed_count = 0
    
    # éå†å¤„ç†
    for index, herb in enumerate(herbs_data):
        name = herb['name']
        
        # æ‰“å°è¿›åº¦
        print(f"[{index + 1}/{len(herbs_data)}] æ­£åœ¨æŠ½å–: {name} ...")
        
        result = extract_knowledge_graph(herb['content'])
        
        if result:
            result['source_name'] = name
            
            # å®æ—¶å†™å…¥æ–‡ä»¶
            with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:
                # è½¬æ¢æˆæ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
                json_str = json.dumps(result, ensure_ascii=False, indent=2)
                # å¦‚æœä¸æ˜¯ç¬¬ä¸€æ¡ï¼ŒåŠ ä¸ªé€—å·
                if index > 0:
                    f.write(",\n")
                f.write(json_str)
            
            print(f"  âœ… å·²ä¿å­˜: {name}")
        
        # é¢‘ç‡é™åˆ¶ä¿æŠ¤
        time.sleep(1)

    # æœ€åé—­åˆ JSON æ•°ç»„
    with open(OUTPUT_FILE, 'a', encoding='utf-8') as f:
        f.write("\n]")

    print("-" * 30)
    print(f"ğŸš€ å…¨éƒ¨ä»»åŠ¡å®Œæˆï¼ç»“æœå·²å­˜å…¥: {OUTPUT_FILE}")